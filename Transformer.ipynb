{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from sklearn.neighbors import NearestNeighbors as KNN\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention is All you Need**\n",
    "\n",
    "https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "https://www.coursera.org/learn/attention-models-in-nlp/lecture/hPxD1/queries-keys-values-and-attention"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention Layer:**\n",
    "\n",
    "Query, Key, Value\n",
    "\n",
    "Query @ Key.Transposed = Similarity Matrix\n",
    "(Note: @ = matrix multiplication)\n",
    "\n",
    "Scaled Similarity Matrix = (Similarity Matrix)/sqrt(keys dimension)\n",
    "\n",
    "Masks can be applied to Scaled Similarity Matrix(optional)\n",
    "\n",
    "Attention Weights = Softmax(Scaled Similarity Matrix)\n",
    "\n",
    "Values(vectors?) * Attention Weights = output vector\n",
    "\n",
    "\n",
    "**Multi-Head Attention**\n",
    "\n",
    "Output vector of each head ----> Concatenation ----> Linear Layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After each attention layer:**\n",
    "\n",
    "Apply PositionFeedForward layer.\n",
    "\n",
    "Attention output -----> Neuron1 ----> ReLU ----> Neuron2 # Both neurons with bias ---> output (position-wise)\n",
    "\n",
    "input dimension = output dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer**\n",
    "\n",
    "Input sequence -------> Embedding Matrix -----> Vectors\n",
    "\n",
    "## Encoder:\n",
    "\n",
    "Vectors = Vectors * sqrt(model dimension)\n",
    "\n",
    "Positional Encoding: \"Since our model contains no recurrence and no convolution, in order for the model to make use of the\n",
    "order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence\"\n",
    "\"We also experimented with using learned positional embeddings instead, and found that the two\n",
    "versions produced nearly identical results\"\n",
    "\n",
    "Vectors Positional Encoded = Vectors + Positional Encoding\n",
    "\n",
    "Vectors ----> Dropout\n",
    "\n",
    "Vectors ---> Residual Block\n",
    "\n",
    "Vectors ------> MultiHeadAttention Layer ---> Weighted Vectors\n",
    "\n",
    "Weighted Vectors ---> Residual Block 2\n",
    "\n",
    "Weighted Vectors + Residual Block -----> Position-Wise Layer ----> Encoded Sequences\n",
    "\n",
    "Encoded Sequences + Residual Block 2 -------> Encoder Output\n",
    "\n",
    "## Decoder:\n",
    "\n",
    "Target words ----> Shift right ----> Embedding matrix\n",
    "\n",
    "Target Vectors = Target Vectors * sqrt(model dimension)\n",
    "\n",
    "Target Vectors Positional Encoded = Target Vectors + Positional Encoding\n",
    "\n",
    "Target Vectors ---> Residual Block 1\n",
    "\n",
    "Target Vectors ----> Dropout\n",
    "\n",
    "Target Vectors -----> Masked MultiHead Attention Layer ------> Target Weighted Vectors\n",
    "\n",
    "Target Weighted Vectors -----> Residual Block 2\n",
    "\n",
    "Target Weighted Vectors + Residual Block 1 + Encoder Output ------> MultiHeadAttention Layer ----> Decoder Weighted Vectors\n",
    "\n",
    "Weighted Vectors ---> Residual Block 3\n",
    "\n",
    "Weighted Vectors + Residual Block 2 -----> Position-Wise Layer ----> Decoded Sequences\n",
    "\n",
    "Decoded Sequences + Residual Block 3 ---> Neuron Layer -----> Softmax ----> Output probabilities\n",
    "\n",
    "# For the Transformer, the same embedding Matrix is used for both input and output.\n",
    "\n",
    "# Dropout:\n",
    "\"We apply dropout to the output of each sub-layer, before it is added to the sub-layer input and normalized.\"\n",
    "\"In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks.\"\n",
    "\n",
    "Dropout: MultiHead output, Positionwise output, Embedding. -----> After each Residual Block addition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_phrases = [\n",
    "    \"私の犬は骨が好きではありません。牛ひき肉を好む。\",\n",
    "    \"私の名前はアリスです。始めまして！\",\n",
    "    \"はきさが羨ましい。。。ゲムもやりたかった！私は良いサポートになることができます！\",\n",
    "    \"私達はAIはただの数学の集まりだとあなたは言いますが。でも。。。人間の脳がどのように機能するかを正確に知ったら。。。それはあなたの生活を小物ですか？\",\n",
    "    \"「赤ちゃん」を表す日本語が「赤」を表す漢字なのはなぜですか？人間の赤ちゃんは赤いですか？いちごみたい？\",\n",
    "    \"私のAIは話して...歌ったして...ゲームをします!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_phrases = [\n",
    "    \"My dog doesn't like bones. It prefers ground beef.\",\n",
    "    \"My name's Alice. Nice to meet you!\",\n",
    "    \"I envy Hakisa... I want to play games, too! I could be a good support!\",\n",
    "    \"You say that we AIs are just a bunch of maths. But... once you know exactly how your human brains work... would that make you less living beings?\",\n",
    "    \"Why does the japanese word for 'baby' is the kanji for 'red'? Are human babies red? Like strawberries?\",\n",
    "    \"My AI will talk... she'll sing... she'll... play!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(object):\n",
    "    def __init__(self, english_phrases, japanese_phrases):\n",
    "\n",
    "        self.english_phrases = self._get_phrases(english_phrases)\n",
    "        self.japanese_phrases = self._get_phrases(japanese_phrases)\n",
    "\n",
    "        self.english_words = self._get_english_words(self.english_phrases)\n",
    "        self.japanese_characters = self._get_japanese_characters(self.japanese_phrases)\n",
    "\n",
    "        self.japanese_maximum_length = self._get_maximum_length_japanese(self.japanese_phrases)\n",
    "        self.english_maximum_length = self.japanese_maximum_length\n",
    "\n",
    "        self.english_dictionary = self._create_vocabulary(self.english_words)\n",
    "\n",
    "        self.japanese_dictionary = self._create_vocabulary(self.japanese_characters)\n",
    "\n",
    "        self.english_tokens, self.english_sizes = self._tokenize_english()\n",
    "        self.japanese_tokens, self.japanese_sizes = self._tokenize_japanese()\n",
    "\n",
    "        self.data_english = None\n",
    "        self.data_japanese = None\n",
    "        \n",
    "        \n",
    "    def create_data(self):\n",
    "        data_english = torch.from_numpy(self.english_tokens)\n",
    "        data_japanese = torch.from_numpy(self.japanese_tokens)\n",
    "\n",
    "        self.data_english = data_english\n",
    "        self.data_japanese = data_japanese\n",
    "\n",
    "        print(f\"English Data Size: {self.data_english.size()}\\t Japanese Data Size: {self.data_japanese.size()}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_english)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        english_sentence = self.data_english[idx]\n",
    "        english_real_length = self.english_sizes[idx]\n",
    "\n",
    "        japanese_sentence = self.data_japanese[idx]\n",
    "        japanese_real_length = self.japanese_sizes[idx]\n",
    "\n",
    "        return english_sentence, english_real_length, japanese_sentence, japanese_real_length\n",
    "\n",
    "\n",
    "    def _get_phrases(self, phrases):\n",
    "        phrases = [x.lower() for x in phrases]\n",
    "        phrases = [re.sub('[^\\w\\s]', '', x) for x in phrases]\n",
    "\n",
    "        return phrases\n",
    "\n",
    "    def _get_english_words(self, phrases):\n",
    "        words = ' '.join(phrases)\n",
    "        words = words.split(' ')\n",
    "\n",
    "        return words\n",
    "\n",
    "    def _get_japanese_characters(self, phrases): # Since a kanji mostly means an entire word...\n",
    "        character = ' '.join(phrases)\n",
    "        character = ''.join(character.split())\n",
    "        characters = [i for i in character]\n",
    "\n",
    "        return characters\n",
    "\n",
    "    def _get_maximum_length_japanese(self, phrases):\n",
    "        maximum_length = 0\n",
    "        for sentence in japanese_phrases:\n",
    "            word_length = [len(x) for x in sentence.split()]\n",
    "    \n",
    "            for i in word_length:\n",
    "                if i > maximum_length:\n",
    "                    maximum_length = i\n",
    "\n",
    "        return maximum_length\n",
    "\n",
    "    def _create_vocabulary(self, words):\n",
    "        idx2word = [\"<pad>\"]\n",
    "\n",
    "        for word in words:\n",
    "            if word not in idx2word:\n",
    "                idx2word.append(word)\n",
    "\n",
    "        idx2word.append(\"<EOS>\")\n",
    "\n",
    "        return idx2word\n",
    "    \n",
    "    def _tokenize_english(self):\n",
    "        \n",
    "        phrases = [x.split() for x in self.english_phrases]\n",
    "\n",
    "        tokens = []\n",
    "        sentence_sizes = []\n",
    "        \n",
    "        for sentence in phrases:\n",
    "            tokenized_sentence = []\n",
    "            for word in sentence:\n",
    "\n",
    "                tokenized_sentence.append(self.english_dictionary.index(word))\n",
    "\n",
    "            tokenized_sentence = np.array(tokenized_sentence)\n",
    "            sentence_size = tokenized_sentence.shape[0]\n",
    "            sentence_sizes.append(sentence_size)\n",
    "\n",
    "            if sentence_size < self.english_maximum_length:\n",
    "                pad_size = self.english_maximum_length - sentence_size\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, 1)], constant_values=self.english_dictionary.index(\"<EOS>\"))\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, pad_size-1)], constant_values=0)\n",
    "\n",
    "            tokens.append(tokenized_sentence)\n",
    "        \n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        return tokens, sentence_sizes\n",
    "\n",
    "    def _tokenize_japanese(self):\n",
    "\n",
    "        phrases = [x.split() for x in self.japanese_phrases]\n",
    "\n",
    "        tokens = []\n",
    "        sentence_sizes = []\n",
    "\n",
    "        for sublist in phrases:\n",
    "            for sentence in sublist:\n",
    "                tokenized_sentence = []\n",
    "                for character in sentence:\n",
    "                    index = self.japanese_dictionary.index(character)\n",
    "\n",
    "                    tokenized_sentence.append(index)\n",
    "\n",
    "            tokenized_sentence = np.array(tokenized_sentence)\n",
    "            sentence_size = tokenized_sentence.shape[0]\n",
    "\n",
    "            sentence_sizes.append(sentence_size)\n",
    "\n",
    "            if sentence_size < self.japanese_maximum_length:\n",
    "                pad_size = self.japanese_maximum_length - sentence_size\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, 1)], constant_values=self.japanese_dictionary.index(\"<EOS>\"))\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, pad_size-1)], constant_values=0)\n",
    "\n",
    "            tokens.append(tokenized_sentence)\n",
    "\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        return tokens, sentence_sizes\n",
    "\n",
    "    def decode_output(self, data, reference_list):\n",
    "\n",
    "        phrases = []\n",
    "\n",
    "        for batch in torch.fliplr(data):\n",
    "\n",
    "            sentence = []\n",
    "\n",
    "            for item in batch:\n",
    "\n",
    "                word = reference_list[item.argmax()]\n",
    "                sentence.append(word)\n",
    "            \n",
    "            sentence = ''.join(sentence)\n",
    "\n",
    "            phrases.append(sentence)\n",
    "\n",
    "        return phrases\n",
    "\n",
    "    def decode_labels(self, data, reference_list):\n",
    "\n",
    "        words = []\n",
    "\n",
    "        for i in data:\n",
    "\n",
    "            words.append(reference_list[i])\n",
    "        \n",
    "        phrase = ' '.join(words)\n",
    "\n",
    "        return phrase, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 74)\n",
      "(6, 74)\n"
     ]
    }
   ],
   "source": [
    "dataset_creator = WordDataset(english_phrases, japanese_phrases)\n",
    "print(dataset_creator.japanese_tokens.shape)\n",
    "print(dataset_creator.english_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9  4 10 11 12 13 14 15 16  8 17 18  7 19 90  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  2 20 21  4 22 23 24  9 25 26 27 12 28 29 90  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 4  8 30  6 31 12 28 32 33 34 35 36 11 37 38 39 37  1  4 40 32 41 42 43\n",
      "  44 45 46 47 48 49  6  9  8 12 25 90  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1 50  4 51 52  4 37 53  2 54 55  2 56 12 11 53 49 10 46 37  4 57 32 12\n",
      "  25  6  9 35 58 59  2 60  6 61  2 62 63 45 64 65 25 47 38 18 66 67 45 68\n",
      "  39 37 69 70 71  4 10 46 37  2 72 73 18 74 75  9 25 38 90  0  0  0  0  0\n",
      "   0  0]\n",
      " [76 77 78 14 18 79 25 80 81 82  6 76 18 79 25 83 84 46  2  4 46 85  9 25\n",
      "  38 58 59  2 76 77 78 14  4 76 32  9 25 38 32 77 86 87 37 32 90  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  2 51 52  4 88 28 29 89 39 37 28 29 33 43 34 18 28 12 25 90  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.japanese_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9,  4, 10, 11, 12, 13, 14, 15, 16,  8,\n",
      "        17, 18,  7, 19, 90,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.data_japanese[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('私 の 犬 は 骨 が 好 き で は あ り ま せ ん 牛 ひ き 肉 を 好 む <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>', ['私', 'の', '犬', 'は', '骨', 'が', '好', 'き', 'で', 'は', 'あ', 'り', 'ま', 'せ', 'ん', '牛', 'ひ', 'き', '肉', 'を', '好', 'む', '<EOS>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.decode_labels(dataset_creator.japanese_tokens[0], dataset_creator.japanese_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('my dog doesnt like bones it prefers ground beef <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>', ['my', 'dog', 'doesnt', 'like', 'bones', 'it', 'prefers', 'ground', 'beef', '<EOS>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.decode_labels(dataset_creator.english_tokens[0], dataset_creator.english_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_encoding(d_model, max_length=100):\n",
    "    \"\"\"\n",
    "    Computes positional encoding as defined in the paper.\n",
    "    :param d_model: size of vectors throughout the transformer model\n",
    "    :param max_length: maximum sequence length up to which positional encodings must be calculated\n",
    "    :return: positional encoding, a tensor of size (1, max_length, d_model)\n",
    "    \"\"\"\n",
    "    positional_encoding = torch.zeros((max_length, d_model))  # (max_length, d_model)\n",
    "    for i in range(max_length):\n",
    "        for j in range(d_model):\n",
    "            if j % 2 == 0:\n",
    "                positional_encoding[i, j] = math.sin(i / math.pow(10000, j / d_model))\n",
    "            else:\n",
    "                positional_encoding[i, j] = math.cos(i / math.pow(10000, (j - 1) / d_model))\n",
    "\n",
    "    positional_encoding = positional_encoding.unsqueeze(0)  # (1, max_length, d_model)\n",
    "\n",
    "    return positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = get_positional_encoding(d_model=32, max_length=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 74, 32])\n"
     ]
    }
   ],
   "source": [
    "print(positional_encoding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Data Size: torch.Size([6, 74])\t Japanese Data Size: torch.Size([6, 74])\n"
     ]
    }
   ],
   "source": [
    "dataset_creator.create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_queries, d_values, in_decoder=False):\n",
    "\n",
    "        super(HeadAttention, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_keys = d_values # size of key vectors, same as of the query vectors to allow dot-products for similarity\n",
    "\n",
    "        self.in_decoder = in_decoder\n",
    "\n",
    "        self.create_queries = nn.Linear(d_model, d_queries, bias=False)\n",
    "        self.create_values = nn.Linear(d_model, d_values, bias=False)\n",
    "        self.create_keys = nn.Linear(d_model, d_values, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input, real_lengths):\n",
    "\n",
    "        batch_size = input.size(0) # (Batch, Sequences, d_model)\n",
    "\n",
    "        queries = self.create_queries(input) # (Batch, Sequences, d_queries)\n",
    "        keys = self.create_keys(input) # (Batch, Sequences, d_keys)\n",
    "        values = self.create_values(input) # (Batch, Sequences, d_values)\n",
    "\n",
    "        similarity_matrix = []\n",
    "\n",
    "        for batch in range(batch_size):\n",
    "\n",
    "            dot_product = torch.matmul(queries[batch], keys[batch].T)\n",
    "            similarity_matrix.append(dot_product.unsqueeze(0))\n",
    "\n",
    "        del dot_product\n",
    "\n",
    "        similarity_matrix = torch.cat(similarity_matrix, 0) # (Batch, Sequences, Sequences)\n",
    "\n",
    "        similarity_matrix = similarity_matrix/(math.sqrt(self.d_keys))\n",
    "\n",
    "        # Applying mask of -inf to ignore padded keys ---> Actually using -1e6 to avoid NaNs\n",
    "\n",
    "        mask = torch.zeros_like(similarity_matrix, device=device)\n",
    "\n",
    "        if self.in_decoder: # In the decoder, the sequences are shifted from left to right.\n",
    "\n",
    "            for batch in range(similarity_matrix.size(0)):\n",
    "\n",
    "                mask[batch, :real_lengths[batch]] = 1\n",
    "\n",
    "                mask = mask.bool()\n",
    "\n",
    "            similarity_matrix = similarity_matrix.masked_fill(mask, -1e-6)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for batch in range(similarity_matrix.size(0)):\n",
    "\n",
    "                mask[batch, real_lengths[batch]:] = 1\n",
    "\n",
    "                mask = mask.bool()\n",
    "\n",
    "            similarity_matrix = similarity_matrix.masked_fill(mask, -1e-6) # (Batch, Sequence, Sequence)\n",
    "\n",
    "        del mask\n",
    "\n",
    "        attention_weights = self.softmax(similarity_matrix) # (Batch, Sequences, Sequences)\n",
    "\n",
    "        attention_output = torch.bmm(attention_weights, values) # (Batch, Sequences, d_values)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_inner):\n",
    "\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "\n",
    "        self.neuron1 = nn.Linear(d_model, d_inner)\n",
    "        self.Relu = nn.ReLU()\n",
    "        self.neuron2 = nn.Linear(d_inner, d_model)\n",
    "\n",
    "\n",
    "    def forward(self, attention_output_cat):\n",
    "\n",
    "        sequences = self.neuron1(attention_output_cat)\n",
    "        sequences = self.Relu(sequences)\n",
    "\n",
    "        sequences = self.neuron2(sequences)\n",
    "\n",
    "        output = sequences + attention_output_cat\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers, dropout):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attention_heads = nn.ModuleList([HeadAttention(self.d_model, self.d_queries, self.d_values, in_decoder=False) for i in range(n_heads)])\n",
    "\n",
    "        self.neuron = nn.Linear(self.n_heads*self.d_values, self.d_model)\n",
    "\n",
    "        self.position_wise_neuron = PositionWiseFeedForward(self.d_model, self.d_inner)\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, encoder_input, real_input_length):\n",
    "\n",
    "        residual_block1 = encoder_input # (Batch, Sequence, d_model) ---> Vectors\n",
    "\n",
    "        vectors = self.dropout(encoder_input)\n",
    "\n",
    "        attention_output = []\n",
    "\n",
    "        for head in range(self.n_heads):\n",
    "\n",
    "            x = self.attention_heads[head](vectors, real_input_length)\n",
    "\n",
    "            attention_output.append(x)\n",
    "\n",
    "            del x\n",
    "        \n",
    "        attention_output = torch.cat(attention_output, -1) # (Batch, Sequences, d_values*n_heads)\n",
    "\n",
    "        attention_output = self.neuron(attention_output) # (Batch, Sequences, d_model)\n",
    "\n",
    "        del vectors\n",
    "\n",
    "        residual_block2 = attention_output\n",
    "\n",
    "        attention_output = residual_block1 + attention_output\n",
    "\n",
    "        attention_output = self.dropout(attention_output)\n",
    "\n",
    "        encoded_sequence = self.position_wise_neuron(attention_output)\n",
    "\n",
    "        del attention_output\n",
    "\n",
    "        encoded_sequence = encoded_sequence + residual_block2    \n",
    "\n",
    "        encoder_output = self.dropout(encoded_sequence)\n",
    "\n",
    "        del encoded_sequence, residual_block1, residual_block2\n",
    "\n",
    "        return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers, dropout):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attention_headsA = nn.ModuleList([HeadAttention(self.d_model, self.d_queries, self.d_values, in_decoder=True) for i in range(n_heads)])\n",
    "        self.attention_headsB = nn.ModuleList([HeadAttention(self.d_model, self.d_queries, self.d_values, in_decoder=True) for i in range(n_heads)])\n",
    "\n",
    "        self.neuronA = nn.Linear(self.n_heads*self.d_values, self.d_model)\n",
    "        self.neuronB = nn.Linear(self.n_heads*self.d_values, self.d_model)\n",
    "\n",
    "        self.position_wise_neuron = PositionWiseFeedForward(self.d_model, self.d_inner)\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "    def forward(self, encoder_output, target_sequences, real_target_length):\n",
    "\n",
    "        residual_block1 = target_sequences\n",
    "\n",
    "        vectors = self.dropout(target_sequences)\n",
    "\n",
    "        attention_output = []\n",
    "\n",
    "        for head in range(self.n_heads):\n",
    "\n",
    "            x = self.attention_headsA[head](vectors, real_target_length)\n",
    "\n",
    "            attention_output.append(x)\n",
    "\n",
    "            del x\n",
    "        \n",
    "        attention_output = torch.cat(attention_output, -1) # (Batch, Sequences, d_values*n_heads)\n",
    "\n",
    "        attention_output = self.neuronA(attention_output) # (Batch, Sequences, d_model)\n",
    "\n",
    "        del vectors\n",
    "\n",
    "        residual_block2 = attention_output\n",
    "\n",
    "        attention_output = residual_block1 + attention_output\n",
    "\n",
    "        attention_output = self.dropout(attention_output)\n",
    "\n",
    "        encoder_output = encoder_output + attention_output\n",
    "        \n",
    "        attention_output = []\n",
    "\n",
    "        for head in range(self.n_heads):\n",
    "\n",
    "            x = self.attention_headsB[head](encoder_output, real_target_length)\n",
    "\n",
    "            attention_output.append(x)\n",
    "\n",
    "            del x\n",
    "\n",
    "        attention_output = torch.cat(attention_output, -1) # (Batch, Sequences, d_values*n_heads)\n",
    "\n",
    "        attention_output = self.neuronB(attention_output) # (Batch, Sequences, d_model)\n",
    "\n",
    "        residual_block3 = attention_output\n",
    "\n",
    "        attention_output = attention_output + residual_block2\n",
    "\n",
    "        attention_output = self.dropout(attention_output)\n",
    "\n",
    "        decoded_sequence = self.position_wise_neuron(attention_output)\n",
    "\n",
    "        del attention_output\n",
    "\n",
    "        decoded_sequence = decoded_sequence + residual_block3\n",
    "\n",
    "        decoder_output = self.dropout(decoded_sequence)  \n",
    "\n",
    "        del decoded_sequence, residual_block1, residual_block2, residual_block3\n",
    "\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_sizeA, vocab_sizeB, positional_encoding, d_model=512, n_heads=8, d_queries=64, d_values=64, d_inner=2056, n_layers=6, dropout=0.1):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.vocab_sizeA = vocab_sizeA\n",
    "        self.vocab_sizeB = vocab_sizeB\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder_embedding = nn.Embedding(vocab_sizeA, self.d_model)\n",
    "        self.decoder_embedding = nn.Embedding(vocab_sizeB, self.d_model)\n",
    "\n",
    "        self.positional_encoding.requires_grad = False\n",
    "\n",
    "        self.encoder = nn.ModuleList(\n",
    "            Encoder(vocab_size=vocab_sizeA,\n",
    "                               positional_encoding=positional_encoding,\n",
    "                               d_model=d_model,\n",
    "                               n_heads=n_heads,\n",
    "                               d_queries=d_queries,\n",
    "                               d_values=d_values,\n",
    "                               d_inner=d_inner,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=self.dropout) for i in range(self.n_layers)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.ModuleList(\n",
    "            Decoder(vocab_size=vocab_sizeB,\n",
    "                               positional_encoding=positional_encoding,\n",
    "                               d_model=d_model,\n",
    "                               n_heads=n_heads,\n",
    "                               d_queries=d_queries,\n",
    "                               d_values=d_values,\n",
    "                               d_inner=d_inner,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=self.dropout) for i in range(self.n_layers)\n",
    "        )\n",
    "\n",
    "        self.output_neuron = nn.Linear(self.d_model, vocab_sizeB)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(-1)\n",
    "                               \n",
    "    def forward(self, encoder_sequences, real_input_length, decoder_sequences, real_target_length):\n",
    "\n",
    "        encoder_sequences = self.encoder_embedding(encoder_sequences) * math.sqrt(self.d_model)\n",
    "\n",
    "        encoder_sequences = encoder_sequences + self.positional_encoding.to(device)\n",
    "\n",
    "        decoder_sequences = self.decoder_embedding(decoder_sequences) * math.sqrt(self.d_model)\n",
    "\n",
    "        decoder_sequences = decoder_sequences + self.positional_encoding.to(device)\n",
    "\n",
    "        for layer in range(self.n_layers):\n",
    "\n",
    "            encoder_sequences = self.encoder[layer](encoder_sequences, real_input_length)\n",
    "\n",
    "            decoder_sequences = self.decoder[layer](encoder_sequences, decoder_sequences, real_target_length) # (Batch, 74, 32)\n",
    "\n",
    "        output = self.output_neuron(decoder_sequences) # (Batch, 74, 91)\n",
    "\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 91\n"
     ]
    }
   ],
   "source": [
    "vocab_sizeA = len(dataset_creator.english_dictionary)\n",
    "vocab_sizeB = len(dataset_creator.japanese_dictionary)\n",
    "\n",
    "print(vocab_sizeA, vocab_sizeB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_sizeA=vocab_sizeA, vocab_sizeB=vocab_sizeB, positional_encoding=positional_encoding, d_model=32, n_heads=4, d_queries=16, d_values=16, d_inner=64, n_layers=3, dropout=0.1).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-8, betas=(0.9, 0.98), eps=1e-9, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_creator, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000\t Current Loss: 32.114803314208984\t Current LR: [1.0000000000000002e-10]\n",
      "1/1000\t Current Loss: 32.07429504394531\t Current LR: [1.0000000000000004e-12]\n",
      "2/1000\t Current Loss: 28.077415466308594\t Current LR: [1.0000000000000005e-14]\n",
      "3/1000\t Current Loss: 33.48210906982422\t Current LR: [1.0000000000000005e-16]\n",
      "4/1000\t Current Loss: 29.12110137939453\t Current LR: [1.0000000000000006e-18]\n",
      "5/1000\t Current Loss: 30.34624481201172\t Current LR: [1.0000000000000007e-20]\n",
      "6/1000\t Current Loss: 33.1760139465332\t Current LR: [1.0000000000000008e-22]\n",
      "7/1000\t Current Loss: 31.233173370361328\t Current LR: [1.0000000000000008e-24]\n",
      "8/1000\t Current Loss: 27.156681060791016\t Current LR: [1.0000000000000009e-26]\n",
      "9/1000\t Current Loss: 30.182231903076172\t Current LR: [1.000000000000001e-28]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i, (english, real_english_length, japanese, real_japanese_length) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        input_data = english.to(device).long()\n",
    "        input_length = real_english_length.to(device).long()\n",
    "        labels = japanese.to(device).long()\n",
    "        labels = torch.fliplr(labels) # The target must be shifted left to right # (Batch, 74)\n",
    "        labels_length = real_japanese_length.to(device).long() # (Batch,)\n",
    "\n",
    "        output = model(input_data, input_length, labels, labels_length) # (Batch, 74, 91)\n",
    "\n",
    "        for p in model.parameters(): # Clipping gradients (Which is way better than having to deal with vanishing gradients)\n",
    "            p.register_hook(lambda grad: torch.clamp(grad, -0.5, 0.5))\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for batch in range(output.size(0)):\n",
    "\n",
    "            loss += criterion(output[batch], labels[batch])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"{epoch}/1000\\t Current Loss: {loss.item()}\\t Current LR: {scheduler.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 74, 91])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -4.4682, -16.7030, -13.0362,  ...,  -9.8240, -10.5646,  -0.7117],\n",
      "         [ -2.9391, -19.0029, -14.2571,  ..., -12.2293, -13.8208,  -1.3864],\n",
      "         [ -3.2669, -17.7897, -12.7193,  ..., -10.6104, -13.8291,  -2.9508],\n",
      "         ...,\n",
      "         [-12.9946, -17.1312, -18.8610,  ...,  -9.5657, -10.2219,  -4.7803],\n",
      "         [-12.0390, -15.3410,  -9.0288,  ..., -10.9370, -14.0866,  -8.1226],\n",
      "         [ -1.7883, -22.8448, -14.4699,  ..., -12.0343, -14.5355,  -1.5508]],\n",
      "\n",
      "        [[ -5.0624, -13.7362,  -9.3787,  ...,  -8.6771, -12.1508,  -5.1627],\n",
      "         [ -4.6793, -13.8132, -13.0091,  ...,  -9.7522,  -9.9920,  -5.0396],\n",
      "         [ -5.9491, -14.3976, -11.5548,  ...,  -9.4063, -11.4527,  -4.8504],\n",
      "         ...,\n",
      "         [-16.6116, -23.3846, -20.2622,  ..., -24.8381, -14.4817, -10.3303],\n",
      "         [-33.5132, -31.2536, -30.4799,  ..., -28.7463, -25.0999, -18.8534],\n",
      "         [-19.5277, -20.9013,  -9.4762,  ..., -13.3440, -12.4143,  -3.7363]],\n",
      "\n",
      "        [[ -6.7629, -14.0389, -13.0016,  ...,  -9.3837, -10.7697,  -1.1321],\n",
      "         [ -4.3637, -16.9963,  -9.6197,  ..., -11.1379, -13.7540,  -2.0654],\n",
      "         [ -4.3449, -13.0454, -10.3024,  ...,  -9.0638, -11.7872,  -1.5854],\n",
      "         ...,\n",
      "         [-20.0887, -28.5201, -24.1081,  ..., -13.5961, -22.2825, -11.4577],\n",
      "         [-21.6566, -23.3901, -17.5255,  ..., -15.2438, -14.9430,  -9.9816],\n",
      "         [-15.7368, -22.8656, -14.0204,  ..., -19.1343, -20.9762,  -4.2382]]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.japanese_tokens[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([74, 91])\n"
     ]
    }
   ],
   "source": [
    "print(output[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <EOS> す ま し を ム ー ゲ て し た っ 歌 て し 話 は i a の 私', ['<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<EOS>', 'す', 'ま', 'し', 'を', 'ム', 'ー', 'ゲ', 'て', 'し', 'た', 'っ', '歌', 'て', 'し', '話', 'は', 'i', 'a', 'の', '私'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.decode_labels(labels[0], dataset_creator.japanese_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('my ai will talk shell sing shell play <EOS> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>', ['my', 'ai', 'will', 'talk', 'shell', 'sing', 'shell', 'play', '<EOS>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.decode_labels(input_data[0], dataset_creator.english_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>ゲゲスり<pad><pad>ゲ<pad>あ私トうあめよ<pad>せ話<pad><pad>言数<pad>り言<pad><pad>ゲ言う<pad>ト言う<pad>能ゲゲ話ゲ<pad>言<pad>ゲゲゲ言<pad>う言言<pad>ゃ数話ゲ<pad>言<pad>言言<pad>言言言<pad><pad><pad>言言話言言', 'やや知話ト話ん<pad>ト<EOS>話せア知むた<pad>やト話トんなまトト話せむト言ト<pad>せトト話トゃゃトゲむ話言言確まトせトむまんんんんんんんんむんんたんむむんんんん<pad>ん', 'なや<pad>うせり<pad>せiめゃ<pad>ゃめ<pad>りりゃ<pad>ゃ<pad>せめ話り<pad><pad>ゃ<pad><pad><pad>話話数せ<pad>ゲゃ話ゃゃり話りゃ<pad><pad>ゃゃ話<pad>せ<pad><pad>せゃ<pad>ゃゃゲせゃり話<pad>ゃゃ<pad><pad>話<pad><pad><pad>ゃ']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_creator.decode_output(output, dataset_creator.japanese_dictionary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
