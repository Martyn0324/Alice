{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from sklearn.neighbors import NearestNeighbors as KNN\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code: https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Machine-Translation\n",
    "\n",
    "\n",
    "**I LOVE YOU SO MUCH BRO <3 <3 <3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "japanese_phrases = [\n",
    "    \"私の犬は骨が好きではありません。牛ひき肉を好む。\",\n",
    "    \"私の名前はアリスです。始めまして！\",\n",
    "    \"はきさが羨ましい。。。ゲムもやりたかった！私は良いサポートになることができます！\",\n",
    "    \"私達はAIはただの数学の集まりだとあなたは言いますが。でも。。。人間の脳がどのように機能するかを正確に知ったら。。。それはあなたの生活を小物ですか？\",\n",
    "    \"「赤ちゃん」を表す日本語が「赤」を表す漢字なのはなぜですか？人間の赤ちゃんは赤いですか？いちごみたい？\",\n",
    "    \"私のAIは話して...歌ったして...ゲームをします!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_phrases = [\n",
    "    \"My dog doesn't like bones. It prefers ground beef.\",\n",
    "    \"My name's Alice. Nice to meet you!\",\n",
    "    \"I envy Hakisa... I want to play games, too! I could be a good support!\",\n",
    "    \"You say that we AIs are just a bunch of maths. But... once you know exactly how your human brains work... would that make you less living beings?\",\n",
    "    \"Why does the japanese word for 'baby' is the kanji for 'red'? Are human babies red? Like strawberries?\",\n",
    "    \"My AI will talk... she'll sing... she'll... play!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(object):\n",
    "    def __init__(self, english_phrases, japanese_phrases):\n",
    "\n",
    "        self.english_phrases = self._get_phrases(english_phrases)\n",
    "        self.japanese_phrases = self._get_phrases(japanese_phrases)\n",
    "\n",
    "        self.english_words = self._get_english_words(self.english_phrases)\n",
    "        self.japanese_characters = self._get_japanese_characters(self.japanese_phrases)\n",
    "\n",
    "        self.japanese_maximum_length = self._get_maximum_length_japanese(self.japanese_phrases)\n",
    "        self.english_maximum_length = self.japanese_maximum_length\n",
    "\n",
    "        self.english_dictionary = self._create_dictionary(self.english_words)\n",
    "        self._normalize(self.english_dictionary)\n",
    "\n",
    "        self.japanese_dictionary = self._create_dictionary(self.japanese_characters)\n",
    "        self._normalize(self.japanese_dictionary)\n",
    "\n",
    "        self.english_tokens = self._tokenize_english()\n",
    "        self.japanese_tokens = self._tokenize_japanese()\n",
    "\n",
    "        self.data_english = None\n",
    "        self.data_japanese = None\n",
    "        \n",
    "        \n",
    "    def create_data(self):\n",
    "        data_english = torch.from_numpy(self.english_tokens)\n",
    "        data_japanese = torch.from_numpy(self.japanese_tokens)\n",
    "\n",
    "        data_english = data_english.unsqueeze(-1)\n",
    "        data_japanese = data_japanese.unsqueeze(-1)\n",
    "\n",
    "        #self.data_english = torch.unsequeeze(self.data_english, -1)\n",
    "        #self.data_japanese = torch.unsequeeze(self.data_japanese, -1)\n",
    "\n",
    "        self.data_english = data_english\n",
    "        self.data_japanese = data_japanese\n",
    "\n",
    "        print(f\"English Data Size: {self.data_english.size()}\\t Japanese Data Size: {self.data_japanese.size()}\")\n",
    "\n",
    "    def detokenize(self, data, reference_dict):\n",
    "        data = data.cpu().numpy()\n",
    "        values = list(reference_dict.values())\n",
    "\n",
    "        values = np.array(values).reshape(-1,1)\n",
    "\n",
    "        knn = KNN(n_neighbors=1, algorithm='kd_tree').fit(values)\n",
    "\n",
    "        _, index = knn.kneighbors(data)\n",
    "\n",
    "        keys = list(reference_dict.keys())\n",
    "\n",
    "        words = []\n",
    "\n",
    "        for subarray in index:\n",
    "            for i in subarray:\n",
    "                words.append(keys[i])\n",
    "        \n",
    "        phrase = ' '.join(words)\n",
    "\n",
    "        return phrase, words\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_english)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        english_sentence = self.data_english[idx]\n",
    "        japanese_sentence = self.data_japanese[idx]\n",
    "\n",
    "        return english_sentence, japanese_sentence\n",
    "\n",
    "\n",
    "    def _get_phrases(self, phrases):\n",
    "        phrases = [x.lower() for x in phrases]\n",
    "        phrases = [re.sub('[^\\w\\s]', '', x) for x in phrases]\n",
    "\n",
    "        return phrases\n",
    "\n",
    "    def _get_english_words(self, phrases):\n",
    "        words = ' '.join(phrases)\n",
    "        words = words.split(' ')\n",
    "\n",
    "        return words\n",
    "\n",
    "    def _get_japanese_characters(self, phrases): # Since a kanji mostly means an entire word...\n",
    "        character = ' '.join(phrases)\n",
    "        character = ''.join(character.split())\n",
    "        characters = [i for i in character]\n",
    "\n",
    "        return characters\n",
    "\n",
    "    def _get_maximum_length_japanese(self, phrases):\n",
    "        maximum_length = 0\n",
    "        for sentence in japanese_phrases:\n",
    "            word_length = [len(x) for x in sentence.split()]\n",
    "    \n",
    "            for i in word_length:\n",
    "                if i > maximum_length:\n",
    "                    maximum_length = i\n",
    "\n",
    "        return maximum_length\n",
    "\n",
    "    def _create_dictionary(self, words):\n",
    "        idx2word = []\n",
    "        word2idx = {}\n",
    "        for word in words:\n",
    "            if word not in word2idx:\n",
    "                idx2word.append(word)\n",
    "                word2idx[word] = len(idx2word) - 1\n",
    "\n",
    "        word2idx['<EOS>'] = len(idx2word) # Adding an End of Sentence tag to improve model's accuracy\n",
    "\n",
    "        return word2idx\n",
    "\n",
    "    def _normalize(self, dictionary):\n",
    "        maximum = max(dictionary.values())\n",
    "\n",
    "        for word, value in dictionary.items():\n",
    "\n",
    "            scaled_value = (value-0)*2.0 / (maximum - 0)-1.0\n",
    "\n",
    "            #scaled_value = scaled_value * 10.0 # Not really sure if increasing values range actually helps or disturbs the model\n",
    "\n",
    "            dictionary[word] = scaled_value\n",
    "    \n",
    "    def _tokenize_english(self):\n",
    "        \n",
    "        phrases = [x.split() for x in self.english_phrases]\n",
    "\n",
    "        tokens = []\n",
    "        \n",
    "        for sentence in phrases:\n",
    "            tokenized_sentence = []\n",
    "            for word in sentence:\n",
    "                value = self.english_dictionary.get(word)\n",
    "\n",
    "                tokenized_sentence.append(value)\n",
    "\n",
    "            tokenized_sentence = np.array(tokenized_sentence)\n",
    "            sentence_size = tokenized_sentence.shape[0]\n",
    "\n",
    "            if sentence_size < self.english_maximum_length:\n",
    "                pad_size = self.english_maximum_length - sentence_size\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, pad_size)], constant_values=1.0) # Remember: <'EOS'> token is 10.0\n",
    "\n",
    "            tokens.append(tokenized_sentence)\n",
    "        \n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def _tokenize_japanese(self):\n",
    "\n",
    "        phrases = [x.split() for x in self.japanese_phrases]\n",
    "\n",
    "        tokens = []\n",
    "\n",
    "        for sublist in phrases:\n",
    "            for sentence in sublist:\n",
    "                tokenized_sentence = []\n",
    "                for character in sentence:\n",
    "                    value = self.japanese_dictionary.get(character)\n",
    "\n",
    "                    tokenized_sentence.append(value)\n",
    "\n",
    "            tokenized_sentence = np.array(tokenized_sentence)\n",
    "            sentence_size = tokenized_sentence.shape[0]\n",
    "\n",
    "            if sentence_size < self.japanese_maximum_length:\n",
    "                pad_size = self.japanese_maximum_length - sentence_size\n",
    "                tokenized_sentence = np.pad(tokenized_sentence, [(0, pad_size)], constant_values=1.0)\n",
    "\n",
    "            tokens.append(tokenized_sentence)\n",
    "\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 74)\n",
      "(6, 74)\n"
     ]
    }
   ],
   "source": [
    "dataset_creator = WordDataset(english_phrases, japanese_phrases)\n",
    "print(dataset_creator.japanese_tokens.shape)\n",
    "print(dataset_creator.english_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_heads, d_queries, d_values, dropout, in_decoder=False):\n",
    "\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_keys = d_values # size of key vectors, same as of the query vectors to allow dot-products for similarity\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.in_decoder = in_decoder\n",
    "\n",
    "        self.create_queries = nn.Linear(d_model, n_heads*d_queries, bias=False)\n",
    "        self.create_values = nn.Linear(d_model, n_heads*d_values, bias=False)\n",
    "        self.create_keys = nn.Linear(d_model, n_heads*d_values, bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.cast_output = nn.Linear(n_heads*d_values, d_model, bias=False)\n",
    "\n",
    "    def forward(self, query_sequences, key_sequences, value_sequences):\n",
    "\n",
    "        batch_size = query_sequences.size(0)\n",
    "        query_sequences_length = query_sequences.size(1)\n",
    "\n",
    "        self_attention = torch.equal(key_sequences, query_sequences)\n",
    "\n",
    "        residual = query_sequences\n",
    "\n",
    "        queries = self.create_queries(query_sequences)\n",
    "        keys = self.create_keys(key_sequences)\n",
    "        values = self.create_values(value_sequences)\n",
    "\n",
    "        queries = queries.contiguous().view(batch_size, query_sequences_length, self.n_heads, self.d_queries)\n",
    "        queries = queries.permute(0, 2, 1, 3).contiguous().view(batch_size*self.n_heads, query_sequences_length, self.d_queries)\n",
    "\n",
    "        keys = keys.contiguous().view(batch_size, query_sequences_length, self.n_heads, self.d_keys)\n",
    "        keys = keys.permute(0, 2, 1, 3).contiguous().view(batch_size*self.n_heads, query_sequences_length, self.d_keys)\n",
    "\n",
    "        values = values.contiguous().view(batch_size, query_sequences_length, self.n_heads, self.d_values)\n",
    "        values = values.permute(0, 2, 1, 3).contiguous().view(batch_size*self.n_heads, query_sequences_length, self.d_values)\n",
    "\n",
    "\n",
    "        dotproduct = torch.bmm(queries, keys.permute(0, 2, 1))\n",
    "\n",
    "        dotproduct = dotproduct/(math.sqrt(self.d_keys))\n",
    "\n",
    "\n",
    "        if self.in_decoder and self_attention:\n",
    "            not_future_mask = torch.ones_like(dotproduct).tril().bool().to(device)\n",
    "\n",
    "            attention_weights = dotproduct.masked_fill(~not_future_mask, -float('inf'))\n",
    "\n",
    "        attention_weights = self.softmax(dotproduct)\n",
    "\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        sequences = torch.bmm(attention_weights, values)\n",
    "\n",
    "        sequences = sequences.view(batch_size, query_sequences_length, -1)\n",
    "\n",
    "        sequences = self.cast_output(sequences)\n",
    "\n",
    "        sequences = self.dropout(sequences)\n",
    "\n",
    "        output = sequences + residual\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_inner, dropout):\n",
    "\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.neuron1 = nn.Linear(d_model, d_inner)\n",
    "\n",
    "        self.Relu = nn.ReLU()\n",
    "\n",
    "        self.neuron2 = nn.Linear(d_inner, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, sequences):\n",
    "\n",
    "        residual = sequences\n",
    "\n",
    "        #sequences = self.layer_norm(sequences) # Layer norm only accepts integers as arguments. Perhaps using simple BatchNormalization might be a good alternative to this\n",
    "\n",
    "        sequences = self.neuron1(sequences)\n",
    "        sequences = self.Relu(sequences)\n",
    "        sequences = self.dropout(sequences)\n",
    "\n",
    "        sequences = self.neuron2(sequences)\n",
    "        sequences = self.dropout(sequences)\n",
    "\n",
    "        output = sequences + residual\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers, dropout):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.positional_encoding.requires_grad = False\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([self.make_encoder_layer() for i in range(n_layers)])\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def make_encoder_layer(self):\n",
    "        encoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
    "                                                          n_heads=self.n_heads,\n",
    "                                                          d_queries=self.d_queries,\n",
    "                                                          d_values=self.d_values,\n",
    "                                                          dropout=self.dropout,\n",
    "                                                          in_decoder=False),\n",
    "                                       PositionWiseFeedForward(d_model=self.d_model,\n",
    "                                                             d_inner=self.d_inner,\n",
    "                                                             dropout=self.dropout)])\n",
    "\n",
    "        return encoder_layer\n",
    "\n",
    "    def forward(self, encoder_sequences):\n",
    "\n",
    "        encoder_sequences = encoder_sequences * math.sqrt(self.d_model) + self.positional_encoding.to(device)\n",
    "\n",
    "        encoder_sequences = self.dropout(encoder_sequences)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "\n",
    "            encoder_sequences = layer[0](query_sequences=encoder_sequences, key_sequences=encoder_sequences, value_sequences=encoder_sequences)\n",
    "            \n",
    "            encoder_sequences = layer[1](sequences=encoder_sequences)\n",
    "\n",
    "        #encoder_sequences = self.layer_norm(encoder_sequences) # For I will not use embedding and integers unless someone proves to me that it's for the best\n",
    "\n",
    "        return encoder_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, positional_encoding, d_model, n_heads, d_queries, d_values, d_inner, n_layers, dropout):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.positional_encoding.requires_grad = False\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([self.make_decoder_layer() for i in range(n_layers)])\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.neuron = nn.Linear(d_model, 1)\n",
    "\n",
    "    def make_decoder_layer(self):\n",
    "\n",
    "        decoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
    "                                                          n_heads=self.n_heads,\n",
    "                                                          d_queries=self.d_queries,\n",
    "                                                          d_values=self.d_values,\n",
    "                                                          dropout=self.dropout,\n",
    "                                                          in_decoder=True),\n",
    "                                       MultiHeadAttention(d_model=self.d_model,\n",
    "                                                          n_heads=self.n_heads,\n",
    "                                                          d_queries=self.d_queries,\n",
    "                                                          d_values=self.d_values,\n",
    "                                                          dropout=self.dropout,\n",
    "                                                          in_decoder=True),\n",
    "                                       PositionWiseFeedForward(d_model=self.d_model,\n",
    "                                                             d_inner=self.d_inner,\n",
    "                                                             dropout=self.dropout)])\n",
    "\n",
    "        return decoder_layer\n",
    "\n",
    "    def forward(self, decoder_sequences, encoder_sequences):\n",
    "\n",
    "        decoder_sequences = decoder_sequences * math.sqrt(self.d_model) + self.positional_encoding.to(device)\n",
    "\n",
    "        decoder_sequences = self.dropout(decoder_sequences)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "\n",
    "            decoder_sequences = layer[0](query_sequences=decoder_sequences, key_sequences=decoder_sequences, value_sequences=decoder_sequences)\n",
    "\n",
    "            decoder_sequences = layer[1](query_sequences=decoder_sequences, key_sequences=encoder_sequences, value_sequences=encoder_sequences)\n",
    "\n",
    "            decoder_sequences = layer[2](sequences=decoder_sequences)\n",
    "\n",
    "        #decoder_sequences = self.layer_norm(decoder_sequences)\n",
    "\n",
    "        output = self.neuron(decoder_sequences)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, positional_encoding, d_model=512, n_heads=8, d_queries=64, d_values=64, d_inner=2056, n_layers=6, dropout=0.1):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.positional_encoding = positional_encoding\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_queries = d_queries\n",
    "        self.d_values = d_values\n",
    "        self.d_inner = d_inner\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder = Encoder(positional_encoding=positional_encoding,\n",
    "                               d_model=d_model,\n",
    "                               n_heads=n_heads,\n",
    "                               d_queries=d_queries,\n",
    "                               d_values=d_values,\n",
    "                               d_inner=d_inner,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=self.dropout)\n",
    "\n",
    "        self.decoder = Decoder(positional_encoding=positional_encoding,\n",
    "                               d_model=d_model,\n",
    "                               n_heads=n_heads,\n",
    "                               d_queries=d_queries,\n",
    "                               d_values=d_values,\n",
    "                               d_inner=d_inner,\n",
    "                               n_layers=n_layers,\n",
    "                               dropout=self.dropout)\n",
    "                               \n",
    "    def forward(self, encoder_sequences, decoder_sequences):\n",
    "\n",
    "        encoder_sequences = self.encoder(encoder_sequences)\n",
    "\n",
    "        decoder_sequences = self.decoder(decoder_sequences, encoder_sequences)\n",
    "\n",
    "        return decoder_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_encoding(d_model, max_length=100):\n",
    "    \"\"\"\n",
    "    Computes positional encoding as defined in the paper.\n",
    "    :param d_model: size of vectors throughout the transformer model\n",
    "    :param max_length: maximum sequence length up to which positional encodings must be calculated\n",
    "    :return: positional encoding, a tensor of size (1, max_length, d_model)\n",
    "    \"\"\"\n",
    "    positional_encoding = torch.zeros((max_length, d_model))  # (max_length, d_model)\n",
    "    for i in range(max_length):\n",
    "        for j in range(d_model):\n",
    "            if j % 2 == 0:\n",
    "                positional_encoding[i, j] = math.sin(i / math.pow(10000, j / d_model))\n",
    "            else:\n",
    "                positional_encoding[i, j] = math.cos(i / math.pow(10000, (j - 1) / d_model))\n",
    "\n",
    "    positional_encoding = positional_encoding.unsqueeze(0)  # (1, max_length, d_model)\n",
    "\n",
    "    return positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = get_positional_encoding(d_model=128, max_length=74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(positional_encoding=positional_encoding, d_model=128, n_heads=8, d_queries=32, d_values=32, d_inner=512, n_layers=6, dropout=0.1).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, betas=(0.9, 0.98), eps=1e-9, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Data Size: torch.Size([6, 74, 1])\t Japanese Data Size: torch.Size([6, 74, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset_creator.create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_creator, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000\t Current Loss: 319.5277404785156\n",
      "100/1000\t Current Loss: 160.98880004882812\n",
      "200/1000\t Current Loss: 85.14620208740234\n",
      "300/1000\t Current Loss: 50.97126770019531\n",
      "400/1000\t Current Loss: 24.623180389404297\n",
      "500/1000\t Current Loss: 18.172019958496094\n",
      "600/1000\t Current Loss: 14.908890724182129\n",
      "700/1000\t Current Loss: 14.568280220031738\n",
      "800/1000\t Current Loss: 12.37012767791748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23040/2404104575.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for i, (english, japanese) in enumerate(dataloader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        input_data = english.to(device).float()\n",
    "        labels = japanese.to(device).float()\n",
    "\n",
    "        output = model(input_data, labels)\n",
    "\n",
    "        for p in model.parameters(): # Clipping gradients (Which is way better than having to deal with vanishing gradients)\n",
    "            p.register_hook(lambda grad: torch.clamp(grad, -10, 10))\n",
    "\n",
    "        cost = criterion(output, labels)\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch}/1000\\t Current Loss: {cost.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.505684852600098\n"
     ]
    }
   ],
   "source": [
    "print(cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.2657, -10.0000,   4.0039,  -4.9134, -10.0000, -10.0000, -10.0000,\n",
      "          10.0000,   2.5136,  -6.4799, -10.0000,  10.0000, -10.0000,  -2.1131,\n",
      "          -5.6079, -10.0000,   3.7360,  -6.4160,  10.0000, -10.0000, -10.0000,\n",
      "         -10.0000, -10.0000,  -7.4554, -10.0000, -10.0000, -10.0000, -10.0000,\n",
      "         -10.0000,   8.1758,  -0.1625, -10.0000, -10.0000,  10.0000, -10.0000,\n",
      "          -3.2152,  10.0000, -10.0000,   7.3092,  -9.8058,   3.5286,  10.0000,\n",
      "          -8.6870,  10.0000, -10.0000, -10.0000,   9.6088,   2.1505,  -7.1060,\n",
      "           5.6326,  -4.6410,   1.4897, -10.0000, -10.0000,   7.1478,  -6.0898,\n",
      "         -10.0000,  10.0000,  -9.1414,  10.0000,  10.0000,  10.0000,   5.3322,\n",
      "           2.7692, -10.0000, -10.0000, -10.0000,   9.7994, -10.0000, -10.0000,\n",
      "          -7.5377, -10.0000, -10.0000,   4.2309,   0.9620, -10.0000, -10.0000,\n",
      "           7.6955,  10.0000,  10.0000,  -0.3236,  -4.7607,  10.0000,   2.3023,\n",
      "         -10.0000,   4.2738, -10.0000,  -4.7061, -10.0000,  -3.7875,  -4.8416,\n",
      "         -10.0000, -10.0000, -10.0000,   3.6670, -10.0000,  -0.7263, -10.0000,\n",
      "           5.2702,   0.6058,  -2.2929, -10.0000, -10.0000, -10.0000,  -0.0651,\n",
      "          -9.9858, -10.0000,   4.2243, -10.0000, -10.0000,  10.0000, -10.0000,\n",
      "           1.5366, -10.0000,  -2.0660,  -7.0191,  -6.4186,   0.2628,  -2.2750,\n",
      "         -10.0000,  -8.2188, -10.0000,  -5.2697,  10.0000, -10.0000, -10.0000,\n",
      "         -10.0000,  -3.6002]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.decoder.neuron.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -0.1439],\n",
      "         [  2.4920],\n",
      "         [ -2.6357],\n",
      "         [ -5.6632],\n",
      "         [  3.4646],\n",
      "         [  3.3105],\n",
      "         [ -2.6756],\n",
      "         [ -2.3067],\n",
      "         [ -1.1135],\n",
      "         [  5.3477],\n",
      "         [ -4.4073],\n",
      "         [  0.7893],\n",
      "         [ -0.3086],\n",
      "         [  8.3167],\n",
      "         [ -1.2720],\n",
      "         [  0.9941],\n",
      "         [  1.3653],\n",
      "         [ -0.8380],\n",
      "         [ -2.9647],\n",
      "         [  9.0932],\n",
      "         [ -5.3600],\n",
      "         [ -3.8809],\n",
      "         [  1.2539],\n",
      "         [  5.4797],\n",
      "         [ -4.1944],\n",
      "         [  2.8696],\n",
      "         [  3.8522],\n",
      "         [ -2.1797],\n",
      "         [ -1.8041],\n",
      "         [ -2.8612],\n",
      "         [  5.8377],\n",
      "         [  4.9059],\n",
      "         [  5.1100],\n",
      "         [  4.4704],\n",
      "         [  0.4920],\n",
      "         [  7.3925],\n",
      "         [  1.2245],\n",
      "         [ -3.8782],\n",
      "         [  3.1701],\n",
      "         [ -2.3260],\n",
      "         [  0.6317],\n",
      "         [  5.6589],\n",
      "         [ -4.3303],\n",
      "         [  1.0163],\n",
      "         [  4.9993],\n",
      "         [ -2.1649],\n",
      "         [  2.0287],\n",
      "         [  3.2692],\n",
      "         [ -6.0200],\n",
      "         [ -7.3195],\n",
      "         [  0.4307],\n",
      "         [  4.2562],\n",
      "         [  3.2218],\n",
      "         [  4.3919],\n",
      "         [ -4.0519],\n",
      "         [  3.6308],\n",
      "         [ -3.7607],\n",
      "         [  2.1483],\n",
      "         [ -0.6005],\n",
      "         [  2.6120],\n",
      "         [ -2.1538],\n",
      "         [  1.0807],\n",
      "         [  1.9906],\n",
      "         [ -1.8540],\n",
      "         [  1.6392],\n",
      "         [-10.7220],\n",
      "         [ -2.5607],\n",
      "         [ -0.3854],\n",
      "         [ -0.9975],\n",
      "         [ -0.6032],\n",
      "         [ -1.4211],\n",
      "         [  0.3070],\n",
      "         [  3.5718],\n",
      "         [ -3.1576]],\n",
      "\n",
      "        [[ -0.4751],\n",
      "         [ -5.5920],\n",
      "         [ -1.0558],\n",
      "         [ -2.6644],\n",
      "         [ -6.2662],\n",
      "         [ -3.7139],\n",
      "         [  0.7074],\n",
      "         [  6.4790],\n",
      "         [  6.7202],\n",
      "         [ -2.5686],\n",
      "         [ -2.3371],\n",
      "         [ -0.0597],\n",
      "         [  4.7494],\n",
      "         [  0.4473],\n",
      "         [ -0.5956],\n",
      "         [  7.9681],\n",
      "         [ -2.5315],\n",
      "         [  4.9756],\n",
      "         [  0.4896],\n",
      "         [  2.1284],\n",
      "         [  7.9094],\n",
      "         [ -1.7109],\n",
      "         [  1.2032],\n",
      "         [ -1.5325],\n",
      "         [ -2.7021],\n",
      "         [  2.5585],\n",
      "         [  1.0340],\n",
      "         [  3.1114],\n",
      "         [  1.8861],\n",
      "         [  5.0598],\n",
      "         [ -1.7940],\n",
      "         [  1.9667],\n",
      "         [  2.8238],\n",
      "         [ -2.7066],\n",
      "         [ -4.3530],\n",
      "         [  1.1116],\n",
      "         [ -6.6389],\n",
      "         [  0.9383],\n",
      "         [ -1.7901],\n",
      "         [ -2.8567],\n",
      "         [  2.2897],\n",
      "         [  0.8315],\n",
      "         [ -3.8812],\n",
      "         [ -2.5705],\n",
      "         [  3.5236],\n",
      "         [  2.9831],\n",
      "         [ -1.5600],\n",
      "         [ -3.2509],\n",
      "         [ -0.0425],\n",
      "         [  4.2691],\n",
      "         [ -1.4998],\n",
      "         [  0.1810],\n",
      "         [ -2.6829],\n",
      "         [  2.9929],\n",
      "         [ -8.7271],\n",
      "         [  5.9212],\n",
      "         [ -3.7527],\n",
      "         [  2.9345],\n",
      "         [ -0.4310],\n",
      "         [  1.6049],\n",
      "         [  1.9783],\n",
      "         [ -2.7633],\n",
      "         [  6.1678],\n",
      "         [  0.5638],\n",
      "         [  4.9700],\n",
      "         [  2.8423],\n",
      "         [  6.0482],\n",
      "         [  1.1721],\n",
      "         [  2.2217],\n",
      "         [  2.8677],\n",
      "         [  1.9475],\n",
      "         [ -5.7952],\n",
      "         [ -3.9055],\n",
      "         [ -0.7948]],\n",
      "\n",
      "        [[ -7.0786],\n",
      "         [ -0.1265],\n",
      "         [  0.8142],\n",
      "         [  2.2938],\n",
      "         [ -2.0579],\n",
      "         [ -0.3075],\n",
      "         [ -1.1390],\n",
      "         [  0.4350],\n",
      "         [ -1.5386],\n",
      "         [ -0.0569],\n",
      "         [ -2.1533],\n",
      "         [  0.1134],\n",
      "         [ -0.1938],\n",
      "         [  0.8788],\n",
      "         [  0.0803],\n",
      "         [ -1.2776],\n",
      "         [ -1.5010],\n",
      "         [ -1.8215],\n",
      "         [  2.9995],\n",
      "         [  1.5676],\n",
      "         [ -0.3976],\n",
      "         [  0.9555],\n",
      "         [ -0.3373],\n",
      "         [  3.4576],\n",
      "         [ -4.4099],\n",
      "         [  3.6292],\n",
      "         [ -4.7190],\n",
      "         [  3.7702],\n",
      "         [  0.4761],\n",
      "         [  1.4849],\n",
      "         [ -4.8881],\n",
      "         [  5.4633],\n",
      "         [ -1.9278],\n",
      "         [  1.9462],\n",
      "         [  3.6989],\n",
      "         [ -2.9646],\n",
      "         [ -0.4780],\n",
      "         [  4.7471],\n",
      "         [ -5.3588],\n",
      "         [ -5.3076],\n",
      "         [  3.7620],\n",
      "         [ -1.7019],\n",
      "         [ -4.9180],\n",
      "         [  2.4954],\n",
      "         [  1.7768],\n",
      "         [ -2.4545],\n",
      "         [ -3.8933],\n",
      "         [ -3.9291],\n",
      "         [ -3.8224],\n",
      "         [ -0.1688],\n",
      "         [ -5.1042],\n",
      "         [  1.1742],\n",
      "         [  5.1214],\n",
      "         [  1.5490],\n",
      "         [ -1.2702],\n",
      "         [ -1.1838],\n",
      "         [ -3.0350],\n",
      "         [ -4.2895],\n",
      "         [ -4.0128],\n",
      "         [  0.7410],\n",
      "         [  3.3041],\n",
      "         [ -2.6824],\n",
      "         [  0.4483],\n",
      "         [ -1.2994],\n",
      "         [ -1.0579],\n",
      "         [ -0.8971],\n",
      "         [ 10.9435],\n",
      "         [  1.3271],\n",
      "         [  4.7604],\n",
      "         [  3.1203],\n",
      "         [  3.2030],\n",
      "         [  2.2924],\n",
      "         [ -2.3163],\n",
      "         [  3.6010]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0000],\n",
      "         [-0.9775],\n",
      "         [-0.9551],\n",
      "         [-0.9326],\n",
      "         [-0.9101],\n",
      "         [-0.8876],\n",
      "         [-0.8652],\n",
      "         [-0.8427],\n",
      "         [-0.8202],\n",
      "         [-0.9326],\n",
      "         [-0.7978],\n",
      "         [-0.7753],\n",
      "         [-0.7528],\n",
      "         [-0.7303],\n",
      "         [-0.7079],\n",
      "         [-0.6854],\n",
      "         [-0.6629],\n",
      "         [-0.8427],\n",
      "         [-0.6404],\n",
      "         [-0.6180],\n",
      "         [-0.8652],\n",
      "         [-0.5955],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000]],\n",
      "\n",
      "        [[-1.0000],\n",
      "         [-0.9775],\n",
      "         [ 0.1236],\n",
      "         [ 0.1461],\n",
      "         [-0.9326],\n",
      "         [ 0.9551],\n",
      "         [-0.3933],\n",
      "         [-0.3708],\n",
      "         [ 0.9775],\n",
      "         [-0.1461],\n",
      "         [-0.1910],\n",
      "         [-0.3933],\n",
      "         [-0.3708],\n",
      "         [-0.2809],\n",
      "         [-0.0562],\n",
      "         [-0.2584],\n",
      "         [-0.6180],\n",
      "         [-0.3933],\n",
      "         [-0.7528],\n",
      "         [-0.4607],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000]],\n",
      "\n",
      "        [[-1.0000],\n",
      "         [ 0.1011],\n",
      "         [-0.9326],\n",
      "         [ 0.1236],\n",
      "         [ 0.1461],\n",
      "         [-0.9326],\n",
      "         [-0.1910],\n",
      "         [ 0.1685],\n",
      "         [-0.9775],\n",
      "         [ 0.1910],\n",
      "         [ 0.2135],\n",
      "         [-0.9775],\n",
      "         [ 0.2360],\n",
      "         [-0.7528],\n",
      "         [-0.7753],\n",
      "         [ 0.1685],\n",
      "         [ 0.0787],\n",
      "         [-0.7978],\n",
      "         [ 0.0112],\n",
      "         [-0.1910],\n",
      "         [-0.9326],\n",
      "         [ 0.2584],\n",
      "         [-0.3034],\n",
      "         [-0.7528],\n",
      "         [-0.4607],\n",
      "         [-0.8876],\n",
      "         [-0.8202],\n",
      "         [-0.2360],\n",
      "         [ 0.2809],\n",
      "         [ 0.3034],\n",
      "         [-0.9775],\n",
      "         [ 0.3258],\n",
      "         [-0.8876],\n",
      "         [ 0.3483],\n",
      "         [-0.9775],\n",
      "         [ 0.3708],\n",
      "         [ 0.3933],\n",
      "         [-0.0112],\n",
      "         [ 0.4157],\n",
      "         [ 0.4382],\n",
      "         [-0.4607],\n",
      "         [ 0.0337],\n",
      "         [-0.1685],\n",
      "         [-0.6180],\n",
      "         [ 0.4607],\n",
      "         [ 0.4831],\n",
      "         [-0.0112],\n",
      "         [ 0.5056],\n",
      "         [-0.1461],\n",
      "         [-0.1910],\n",
      "         [ 0.5281],\n",
      "         [ 0.5506],\n",
      "         [ 0.5730],\n",
      "         [-0.9326],\n",
      "         [-0.7978],\n",
      "         [ 0.0112],\n",
      "         [-0.1910],\n",
      "         [-0.9775],\n",
      "         [ 0.5955],\n",
      "         [ 0.6180],\n",
      "         [-0.6180],\n",
      "         [ 0.6404],\n",
      "         [ 0.6629],\n",
      "         [-0.8202],\n",
      "         [-0.4607],\n",
      "         [-0.1685],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000],\n",
      "         [ 1.0000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = output.detach()\n",
    "\n",
    "teste = dataset_creator.detokenize(teste[0], dataset_creator.japanese_dictionary)\n",
    "\n",
    "labels = dataset_creator.detokenize(labels[0], dataset_creator.japanese_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('っ <EOS> 私 私 <EOS> <EOS> 私 私 私 <EOS> 私 本 い <EOS> 私 <EOS> <EOS> き 私 <EOS> 私 私 <EOS> <EOS> 私 <EOS> <EOS> 私 私 私 <EOS> <EOS> <EOS> <EOS> 確 <EOS> <EOS> 私 <EOS> 私 小 <EOS> 私 <EOS> <EOS> 私 <EOS> <EOS> 私 私 能 <EOS> <EOS> <EOS> 私 <EOS> 私 <EOS> む <EOS> 私 <EOS> <EOS> 私 <EOS> 私 私 し 私 む 私 間 <EOS> 私', ['っ', '<EOS>', '私', '私', '<EOS>', '<EOS>', '私', '私', '私', '<EOS>', '私', '本', 'い', '<EOS>', '私', '<EOS>', '<EOS>', 'き', '私', '<EOS>', '私', '私', '<EOS>', '<EOS>', '私', '<EOS>', '<EOS>', '私', '私', '私', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '確', '<EOS>', '<EOS>', '私', '<EOS>', '私', '小', '<EOS>', '私', '<EOS>', '<EOS>', '私', '<EOS>', '<EOS>', '私', '私', '能', '<EOS>', '<EOS>', '<EOS>', '私', '<EOS>', '私', '<EOS>', 'む', '<EOS>', '私', '<EOS>', '<EOS>', '私', '<EOS>', '私', '私', 'し', '私', 'む', '私', '間', '<EOS>', '私'])\n"
     ]
    }
   ],
   "source": [
    "print(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('私 の 犬 は 骨 が 好 き で は あ り ま せ ん 牛 ひ き 肉 を 好 む <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>', ['私', 'の', '犬', 'は', '骨', 'が', '好', 'き', 'で', 'は', 'あ', 'り', 'ま', 'せ', 'ん', '牛', 'ひ', 'き', '肉', 'を', '好', 'む', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>'])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
